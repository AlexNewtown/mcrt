\documentclass[a4paper, twocolumn]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[pdftex, hidelinks,
            pdftitle={Monte Carlo Ray Tracing in a Nutshell},
            pdfauthor={Martin Estgren and Erik S. V. Jansson},
            pdfsubject={Rendering -- Global Illumination},
            pdfkeywords={rendering, global illumination,
                         path tracing, c++}]{hyperref}

\usepackage{bm}
\usepackage{caption}
\usepackage{listings}
\usepackage{booktabs}
\usepackage{mathtools}
\usepackage{subcaption}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{courier}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage[capitalize, noabbrev]{cleveref}
\usepackage[activate={true, nocompatibility}, final,
            tracking=true, kerning=true, spacing=true,
            factor=1100, stretch=10, shrink=10]{microtype}

\DeclareCaptionFormat{modifiedlst}{\rule{\textwidth}{0.85pt}\\[-2.9pt]#1#2#3}
\captionsetup[lstlisting]{format =  modifiedlst,
labelfont=bf,singlelinecheck=off,labelsep=space}
\lstset{basicstyle=\footnotesize\ttfamily,
        breakatwhitespace = false,
        breaklines = true,
        keepspaces = true,
        language = C++,
        showspaces = false,
        showstringspaces = false,
        frame = tb,
        numbers = left,
        numbersep = 5pt,
        xleftmargin = 16pt,
        framexleftmargin = 16pt,
        belowskip = \bigskipamount,
        aboveskip = \bigskipamount,
        escapeinside={<@}{@>}}

\title{\LARGE{\textbf{Monte Carlo Raytracing from Scratch}}}
\author{{\textbf{Martin Estgren}} \;\;\;\;\;\;\;\;\,   {\href{mailto:mares480@student.liu.se}
                                                       {\texttt{<mares480@student.liu.se>}}} \\
        {\textbf{Rasmus Hedin}} \;\;\;\;\;\;\;\;\;\,\, {\href{mailto:rashe877@student.liu.se}
                                                       {\texttt{<rashe877@student.liu.se>}}} \\
        {\textbf{Erik S. V. Jansson}} \;\;\;           {\href{mailto:erija578@student.liu.se}
                                                       {\texttt{<erija578@student.liu.se>}}} \\~\\
        {Link√∂ping University, Sweden}\vspace{-1.0ex}}

\begin{document}
    \maketitle
    \section*{Abstract}

    \newpage \tableofcontents \clearpage

    \section{Introduction} \label{sec:introduction}

        Several fields of industry use \emph{computer graphics} to generate and display synthetic images on a screen; e.g.\ the entertainment industry uses \emph{raytracers} for \emph{rendering} animated movies while \emph{rasterizers} usually are the technology powering real-time video games. Of course, it's also widely used in the engineering and scientific disciplines for visualizing field data, which even have their own sub-field called \emph{scientific visualization}. Since it is such a wide field, we'll only be focusing on the \emph{rendering problem}: the task of converting one \emph{scene description} to an \emph{image} of it.

        Rendering can usually be done in one of two ways, called the \emph{rasterization} and \emph{raytracing} techniques, or, by using some hybrid of these. \emph{Rasterization} is when we geometrically project a scene, composed of primitives, onto an image plane (our camera) and then color the pixels based on a \emph{local lighting model}. Meaning, objects in a scene are \emph{shaded} only based on position, material properties, viewpoint direction, and light source information; never on other objects. Rasterization is very fast since there is hardware dedicated to these operations, and each of these is independent of each other, in other words, it's an \emph{embarrassingly parallel} problem. \emph{Raytracing} on the other hand shoots \emph{rays} from the pixels in the \emph{camera viewplane} and finds \emph{intersections} with geometry in the scene. These rays bounce around the scene by \emph{specular reflection} or \emph{specular transmission}, until it finds a \emph{diffuse surface}, which then \emph{absorbs} it. It's a process by recursion, which approximates \emph{irradiance} falling onto a pixel. Since it takes into account other objects, it's a technique which gives \emph{global illumination}. Unfortunately, raytracing doesn't have full hardware support, but is still fast since it's also an embarrassingly parallel task (done for each sample).

        In this report we'll describe all the party tricks we've used to implement our \emph{Monte Carlo raytracer} from scratch. It simulates all \emph{light transport} effects for \emph{perfectly diffuse} and \emph{perfectly specular} surfaces. We've also implemented \emph{photon mapping} to speed up our convergence rate for higher quality \emph{caustics}. Arbitrary \emph{triangle meshes} can also be rendered and use \emph{bounding volumes} to ignore low-effort intersection tests. Lastly, we also support \emph{quadric geometry}. All of our scene is specified by using a JSON format.

        We continue \cref{sec:introduction} by giving a brief overview of the field and introducing desirable properties for achieving \emph{photorealism} with a model describing it. We then take a excursion through the most notable rendering schemes to solve the \emph{rendering equation}. In \cref{sec:theory_and_method} we break apart our raytracer bit-by-bit and explain each part in turn, along with any relevant theory necessary. We then play around with our raytracer's knobs in \cref{sec:results_and_benchmark} to see if they affect the final render, and more importantly, the rendering time. We'll try to see if there is a balanced trade-off between render quality and speed. After all this, \cref{sec:discussion_and_outlook} concludes the report by critically looking at our implementation and results and also giving insight into what could be improved further.

    \begin{figure}[ht]
        \centering
        \begin{subfigure}{0.48\linewidth}
            \centering
            \label{fig:cornell_box_local_illumination}
            \includegraphics[width=\linewidth]{share/cornell_local_illumination.png}
            \caption{local illumination}
        \end{subfigure} \hfill
        \begin{subfigure}{0.48\linewidth}
            \centering
            \label{fig:cornell_box_global_illumination}
            \includegraphics[width=\linewidth]{share/cornell_global_illumination.png}
            \caption{global illumination}
        \end{subfigure}
        \caption{Two renders of the famous \emph{Cornell box} in our raytracer; comparing both illumination models.}
        \label{fig:cornell_box}
    \end{figure}

    \vspace{-1.5em}

    \subsection{Global\, Illumination} \label{sec:global_illumination}

    A rendering technique is deemed to be \emph{photorealistic} if, after full convergance, it exactly mimics reality. One of the most important ingredients for achieving photorealism is \emph{global illumination}. We can compare \emph{local illumination} and \emph{global illumination} by looking at \cref{fig:cornell_box}. Notice that GI (global illumination) has \emph{color bleeding}, \emph{hard and soft shadows} and \emph{caustics}. These phenomena are not possible in a local model without ``hacks'' like the \emph{shadow mapping} technique.

    \subsection{Rendering Equation} \label{sec:rendering_equation}

        A model describing most light transport phenomena is the \emph{rendering equation}, shown below, presented by \emph{James Kajiya}~\cite{kajiya1986rendering}. All of the rendering schemes are attempts at solving it. We present in the coming sections the most well known rendering techniques. \begin{align*}
            \mathcal{L}_o(\vec{x}, \hat{\omega}_o) &= \mathcal{L}_e(\vec{x}, \hat{\omega}_o) \; +\\
                                                   &+ \int_\Omega \mathcal{L}_i(\vec{x}, \hat{\omega}_i)
                                                      f_r(\vec{x}, \hat{\omega}_i, \hat{\omega}_o)
                                                      (\hat{n}_{x} \cdot \hat{\omega}_i) \, d\hat{\omega}_i
        \end{align*}

    \subsection{Radiosity} \label{sec:radiosity}
    \textit{Radiosity} for computer graphics assumes all surfaces are \emph{perfectly diffuse patches} (e.g. triangles), and builds on the concept of finding the radiance that is transferred between patches in the scene using an iterative process. Each iteration solves the equation below by reflecting radiance for each patch: \begin{equation*}
        B_i = E_i + \rho_i \sum_{j=1}^{n} F_{ij} B_j \; ,
    \end{equation*}
    where \(B_i\) is the \textit{radiosity} of \emph{patch} \(i\), \(E_i\) the \emph{emitted radiosity} by \(i\), \(\rho_i\) is the \textit{surface reflectivity} of \(i\), and the sum defines the \emph{radiance} falling onto \(i\) between each patch in the scene and the patch \(i\), depending on the \emph{form-factor} \(F_{ij}\) (geometric term) of \(i\) and \(j\).

    \begin{figure}[ht]
        \centering
        \includegraphics[width=\linewidth]{share/radiosity.png}
        \caption{Shows how the radiosity technique spreads the radiance in each iteration (render by \emph{H. Elias}).}
        \label{fig:radiosity}
    \end{figure}

    \vspace{-0.5em}

Iterating on the above equations, a discrete approximation of the \textit{rendering equation} is achieved for perfect Lambertian surfaces as the patch size goes infinitesimal and the iterations tends to infinity (but there needs to be some cutoff point, otherwise numerical errors might start appearing). You can see a radiosity-based renderer iterate through a scene in \cref{fig:radiosity}. Some advantages of radiosity over GI techniques that takes into account specular light is that it calculates the radiosity of the full scene and not just based on the camera viewport, making it useful when baking light-maps with the scene. It's a spin-off of the heat transfer equations in thermodynamics into rendering by \emph{Goral et al.}~\cite{goral1984modeling}.

    \subsection{Whitted Raytracing} \label{sec:whitted_raytracing}

    In the \emph{Whitted}~\cite{whitted1980improved} ray tracing method initial rays are emitted from the camera into the scene. The rays will intersect with objects and new reflective and/or refractive rays are spawned. In this method it is assumed that we only have \emph{perfect reflections and refractions}. The direction of a refracted ray is computed with Snell's law given the refractive indices of the materials at the ray intersection point.

    Reflecting and refracting rays will build up a \emph{tree of rays}. When all rays have terminated (i.e. hit a diffuse surface) the radiance at each intersection is computed from the leaf nodes back up to the root node (the camera). The radiance from the child rays of an intersection point contribute to the total radiance leaving each intersection point. \emph{Shadow rays} are sent from each of these points to the light sources, to know if the point is in shadow. If the shadow ray reaches a source of light then it's not in shadow and the light therefore contributes to the total radiance. \cref{fig:raytracing} (a) is being rendered by it.

    \begin{figure}[ht]
        \centering
        \begin{subfigure}{0.48\linewidth}
            \centering
            \label{fig:whitted_raytracing}
            \includegraphics[width=\linewidth]{share/whitted_raytracing.png}
            \caption{Whitted-ish raytracing}
        \end{subfigure} \hfill
        \begin{subfigure}{0.48\linewidth}
            \centering
            \label{fig:monte_carlo_raytracing}
            \includegraphics[width=\linewidth]{share/monte_carlo_raytracing.png}
            \caption{Monte Carlo raytracing}
        \end{subfigure}
        \caption{Renders of \emph{the scene} in \cref{sec:scene_description} using our raytracer in the early and later progress stages.}
        \label{fig:raytracing}
    \end{figure}

    \vspace{-1.5em}

    \subsection{Path Tracing} \label{sec:path_tracing}

    The \emph{path tracing} method works in a similar way to Whitted raytracing, but the reflections and refractions may not always perfect. Instead, when a ray intersects with an object it will be reflected in a \emph{random direction} originating from the \emph{hemisphere} at the intersection point. The rays are be recursively reflected until they intersect with a light source. But since some rays never hit a light source another condition to terminate is needed. The solution is called \emph{Russian roulette}, where rays have a probability of being \emph{absorbed} at the intersection point. This gives the technique an unbiased result. A tree will be built recursively just as before, adding contribution from the child nodes and from the light sources (which may have an area now) with a local lighting model.

    This is a method that needs many \emph{samples} to converge, and thus uses \emph{Monte Carlo integration}; making the \emph{path tracing technique} a \emph{Monte Carlo raytracer}. \cref{fig:raytracing} (b) shows a render of a scene using our Monte Carlo raytracer; we have more interesting light phenomena than Whitted raytracing.

    \subsection{Photon Mapping} \label{sec:photon_mapping}

    One of the main problems with \textit{path tracing} is that it usually takes very long to \emph{converge} to a \emph{noise-less} image. To speed up the raytrace convergence, \emph{H. Jensen} proposed an algorithm where rays with low importance are approximated using a spatial map of how the light sources in the scene deposits flux. These data-structures are called \textit{photon maps}~\cite{jensen1996global} and significantly speed up convergence of a typical \textit{path tracer} by only requiring a bit of extra memory.

    \vspace{0.5em}

    \begin{figure}[ht]
        \centering
        \begin{subfigure}{0.478\linewidth}
            \centering
            \label{fig:cornell_box_photon_map}
            \scalebox{-1}[1]{\includegraphics[width=\linewidth]{share/photon_mapping.png}}
            \caption{direct light photon map}
        \end{subfigure} \hfill
        \begin{subfigure}{0.498\linewidth}
            \centering
            \includegraphics[width=\linewidth]{share/cornell_global_illumination.png}
            \caption{possible raytrace result}
        \end{subfigure}
        \caption{Here the flux coming from the light source is distributed as seen in (a) before we do raytracing.}
        \label{fig:photon_mapping}
    \end{figure}

    \vspace{-0.25em}

    \textit{Photon mapping} is done in two passes. The first pass is done before the \textit{path tracer} as a pre-processing step where photons are emitted from light sources and bounced around the scene in a way similar to the typical \textit{path tracer}. These photons are usually stored in a \emph{balanced kd-tree} whenever they hit a diffuse surface. The second pass is done in conjunction with the \textit{path tracer} where rays with low importance are approximated by photons stored around the terminating scene-intersection. The number of photons to consider is either calculated by a bounding sphere of fixed size or a sphere expanded until it encompasses a fixed number of photons. These photons are then used to approixmate radiance at the intersection point. We'll see later in the report that our implementation uses the ``\emph{fixed sphere radiance estimation}'' approach for this.

In some cases a higher resolusion secondary \textit{photon map} is used to show caustics effects since these are very expensive to do in regular \textit{path tracing}. In this case, photons are only emitted towards specular objects in the scene and in much greater numbers compared to the regular \textit{photon map}. This enables one to get detailed caustic effects cheaply and fast.

    \clearpage

    \section{Theory and Method} \label{sec:theory_and_method}

        \subsection{Scene Description} \label{sec:scene_description}

        \subsection{Ray-Surface Intersections} \label{sec:ray-surface_intersections}
            \subsubsection{Parametric Sphere} \label{sec:parametric_sphere}
            \subsubsection{Triangle Polygon} \label{sec:triangle_polygon}
            \subsubsection{Triangle Mesh} \label{sec:triangle_mesh}

        \subsection{Surface Properties} \label{sec:surface_properties}
            \subsubsection{Lambertian Model} \label{sec:lambertian_model}
            \subsubsection{Oren-Nayar Model} \label{sec:oren-nayar_model}

        \subsection{Direct Light Contributions} \label{sec:direct_light_contributions}
            \subsubsection{Point Light Source} \label{sec:point_light_source}
            \subsubsection{Area Light Source} \label{sec:area_light_source}
            \subsubsection{Monte Carlo Method} \label{sec:monte_carlo_method}

        \subsection{Indirect Light Contributions} \label{sec:indirect_light_contributions}
            \subsubsection{Specular Reflection} \label{sec:specular_reflection}
            \subsubsection{Specular Refraction} \label{sec:specular_refraction}
            \subsubsection{Diffuse Reflection} \label{sec:diffuse_refraction}
            \subsubsection{Russian Roulette} \label{sec:russian_roulette}

        \subsection{Photon Mapping} \label{sec:photon_mapping}
            \subsubsection{Gathering Photons} \label{sec:gathering_photons}
            \subsubsection{Radiance Estimate} \label{sec:radiance_estimate}

        \subsection{Anti-Aliasing} \label{sec:anti-aliasing}

    \section{Results and Benchmark} \label{sec:results_and_benchmark}

    \section{Discussion and Outlook} \label{sec:discussion_and_outlook}

    \newpage % Next column...
    \nocite{*} % Include all.
    \bibliographystyle{abbrv}
    \bibliography{mcrt}
\end{document}
